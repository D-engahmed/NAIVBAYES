{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a714cbe",
   "metadata": {},
   "source": [
    "<style>\n",
    "    table {\n",
    "        border-collapse: collapse;\n",
    "        width: 100%;\n",
    "        margin: 10px 0;\n",
    "        font-size: 16px;\n",
    "    }\n",
    "    th, td {\n",
    "        border: 1px solid #444;\n",
    "        padding: 8px 12px;\n",
    "        text-align: center;\n",
    "    }\n",
    "    th {\n",
    "        background-color: #222;\n",
    "        color: #FFD700; /* Gold text */\n",
    "    }\n",
    "    tr:nth-child(even) {\n",
    "        background-color: #2b2b2b;\n",
    "    }\n",
    "    tr:nth-child(odd) {\n",
    "        background-color: #1e1e1e;\n",
    "    }\n",
    "    td {\n",
    "        color: #e6e6e6; /* Light gray text */\n",
    "    }\n",
    "    h3 {\n",
    "        color: #00ffcc; /* Aqua title */\n",
    "        text-align: center;\n",
    "        font-family: Arial, sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h3>Comparison Between Naive Bayes Classifiers</h3>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Type</th>\n",
    "        <th>When to Use</th>\n",
    "        <th>Assumptions</th>\n",
    "        <th>Example Features</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>GaussianNB</td>\n",
    "        <td>When features are <b>continuous</b> (e.g., height, weight, temperature)</td>\n",
    "        <td>Assumes features follow a <b>normal (Gaussian)</b> distribution</td>\n",
    "        <td>Medical measurements, sensor data</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MultinomialNB</td>\n",
    "        <td>When features are <b>discrete counts</b></td>\n",
    "        <td>Assumes features are <b>non-negative integers</b> (counts)</td>\n",
    "        <td>Word counts in text classification</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>BernoulliNB</td>\n",
    "        <td>When features are <b>binary</b> (0/1)</td>\n",
    "        <td>Assumes features are boolean</td>\n",
    "        <td>Presence/absence of a word, yes/no attributes</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d8130",
   "metadata": {},
   "source": [
    "<style>\n",
    "    table {\n",
    "        border-collapse: collapse;\n",
    "        width: 100%;\n",
    "        margin: 10px 0;\n",
    "        font-size: 16px;\n",
    "    }\n",
    "    th, td {\n",
    "        border: 1px solid #444;\n",
    "        padding: 8px 12px;\n",
    "        text-align: center;\n",
    "    }\n",
    "    th {\n",
    "        background-color: #222;\n",
    "        color: #FFD700; /* Gold text */\n",
    "    }\n",
    "    tr:nth-child(even) {\n",
    "        background-color: #2b2b2b;\n",
    "    }\n",
    "    tr:nth-child(odd) {\n",
    "        background-color: #1e1e1e;\n",
    "    }\n",
    "    td {\n",
    "        color: #e6e6e6; /* Light gray text */\n",
    "    }\n",
    "    h3 {\n",
    "        color: #00ffcc; /* Aqua title */\n",
    "        text-align: center;\n",
    "        font-family: Arial, sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h3>Comparison in short</h3>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Classifier</th>\n",
    "        <th>Best For</th>\n",
    "        <th>Data Type</th>\n",
    "        <th>Example Use Case</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>GaussianNB</td>\n",
    "        <td>Continuous features</td>\n",
    "        <td>Real-valued</td>\n",
    "        <td>Medical diagnosis, sensor readings</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MultinomialNB</td>\n",
    "        <td>Discrete counts</td>\n",
    "        <td>Positive integers</td>\n",
    "        <td>Text classification (word counts)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>BernoulliNB</td>\n",
    "        <td>Binary features</td>\n",
    "        <td>0/1 values</td>\n",
    "        <td>Spam detection, yes/no features</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ade8b3",
   "metadata": {},
   "source": [
    "## 2. Key Formulas\n",
    "\n",
    "All Naive Bayes types are based on **Bayes‚Äô Theorem**:\n",
    "\n",
    "$$\n",
    "P(C \\mid X) \\;=\\; \\frac{P(X \\mid C)\\,P(C)}{P(X)}\n",
    "$$\n",
    "\n",
    "Difference comes in how \\(P(X \\mid C)\\) is calculated:\n",
    "\n",
    "- **GaussianNB**\n",
    "\n",
    "  $$\n",
    "  P(x_i \\mid C) \\;=\\; \\frac{1}{\\sqrt{2\\pi\\sigma_C^2}}\\;\n",
    "  \\exp\\!\\left(-\\frac{(x_i - \\mu_C)^2}{2\\sigma_C^2}\\right)\n",
    "  $$\n",
    "\n",
    "- **MultinomialNB**\n",
    "\n",
    "  Uses the multinomial probability model (suitable for count features such as word counts).\n",
    "\n",
    "- **BernoulliNB**\n",
    "\n",
    "  Uses the Bernoulli distribution (suitable for binary features, 0/1 presence indicators).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d22a47",
   "metadata": {},
   "source": [
    "Got it ‚Äî here‚Äôs a **clear explanation for each Naive Bayes type** along with the formulas, so you understand not only *what* they do, but also *why* they work that way.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Gaussian Naive Bayes (GaussianNB)**\n",
    "\n",
    "**When to use:**\n",
    "\n",
    "* Your features are **continuous values** (like temperature, height, weight, etc.)\n",
    "* The distribution of each feature for each class is **approximately normal (bell-shaped)**.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "* For each feature, it assumes:\n",
    "\n",
    "  $$\n",
    "  x_i \\mid C \\sim \\mathcal{N}(\\mu_C, \\sigma_C^2)\n",
    "  $$\n",
    "\n",
    "  meaning it‚Äôs normally distributed with mean $\\mu_C$ and variance $\\sigma_C^2$ for class $C$.\n",
    "\n",
    "**Formula for likelihood:**\n",
    "\n",
    "$$\n",
    "P(x_i \\mid C) = \\frac{1}{\\sqrt{2\\pi\\sigma_C^2}} \\exp\\left(-\\frac{(x_i - \\mu_C)^2}{2\\sigma_C^2}\\right)\n",
    "$$\n",
    "\n",
    "* This tells us: given class $C$, the chance of seeing feature value $x_i$ depends on how far $x_i$ is from the mean $\\mu_C$ (scaled by the variance).\n",
    "\n",
    "**Example:**\n",
    "\n",
    "* Classifying whether a fruit is an apple or an orange based on its **weight** and **diameter**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Multinomial Naive Bayes (MultinomialNB)**\n",
    "\n",
    "**When to use:**\n",
    "\n",
    "* Your features are **counts** (non-negative integers).\n",
    "* Typically used for **text classification** with bag-of-words features (e.g., number of times each word appears in a document).\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "* Assumes each feature (like a word count) follows a **multinomial distribution** given the class.\n",
    "* The probability of a sample is:\n",
    "\n",
    "$$\n",
    "P(X \\mid C) = \\frac{(\\sum_i x_i)!}{\\prod_i x_i!} \\prod_i P(f_i \\mid C)^{x_i}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $x_i$ = count of feature $i$\n",
    "* $P(f_i \\mid C)$ = probability of feature $i$ appearing in class $C$\n",
    "\n",
    "**Example:**\n",
    "\n",
    "* Spam detection: features = word counts; class = spam or not spam.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Bernoulli Naive Bayes (BernoulliNB)**\n",
    "\n",
    "**When to use:**\n",
    "\n",
    "* Your features are **binary** (0 or 1) indicating presence/absence of something.\n",
    "* Works well for document classification when you only care about whether a word appears, not how many times.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "* Each feature is modeled as a **Bernoulli random variable**:\n",
    "\n",
    "$$\n",
    "P(x_i \\mid C) = p_i^{{x_i}} (1 - p_i)^{(1 - x_i)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $x_i$ = 1 if feature is present, 0 if not\n",
    "* $p_i$ = probability that feature $i$ appears in class $C$\n",
    "\n",
    "**Example:**\n",
    "\n",
    "* Predicting if an email is spam based on whether certain keywords appear at least once.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3706c8bb",
   "metadata": {},
   "source": [
    "| GaussianNB | MultinomialNB | BernoulliNB |\n",
    "|------------|---------------|-------------|\n",
    "| ![GaussianNB](gaussian_nb.gif) | ![MultinomialNB](multinomial_nb.gif) | ![BernoulliNB](bernoulli_nb.gif) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1660c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model  Accuracy\n",
      "0     GaussianNB  0.893333\n",
      "1  MultinomialNB  0.393333\n",
      "2    BernoulliNB  0.453333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------\n",
    "# 1) GaussianNB Example (Continuous Data)\n",
    "# -------------------------\n",
    "X_gauss, y_gauss = make_classification(n_samples=500, n_features=5, n_informative=3, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_gauss, y_gauss, test_size=0.3, random_state=42)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "acc_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "\n",
    "# -------------------------\n",
    "# 2) MultinomialNB Example (Count Data)\n",
    "# -------------------------\n",
    "# Simulate counts\n",
    "X_multi = np.random.randint(0, 10, size=(500, 5))\n",
    "y_multi = np.random.randint(0, 2, size=500)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_multi, y_multi, test_size=0.3, random_state=42)\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred_mnb = mnb.predict(X_test)\n",
    "acc_mnb = accuracy_score(y_test, y_pred_mnb)\n",
    "\n",
    "# -------------------------\n",
    "# 3) BernoulliNB Example (Binary Data)\n",
    "# -------------------------\n",
    "# Simulate binary features\n",
    "X_bern = np.random.randint(0, 2, size=(500, 5))\n",
    "y_bern = np.random.randint(0, 2, size=500)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bern, y_bern, test_size=0.3, random_state=42)\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "y_pred_bnb = bnb.predict(X_test)\n",
    "acc_bnb = accuracy_score(y_test, y_pred_bnb)\n",
    "\n",
    "# -------------------------\n",
    "# Summary Table\n",
    "# -------------------------\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"GaussianNB\", \"MultinomialNB\", \"BernoulliNB\"],\n",
    "    \"Accuracy\": [acc_gnb, acc_mnb, acc_bnb]\n",
    "})\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967c3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import HTML, display\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.colors import ListedColormap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set dark theme for Jupyter Notebook\n",
    "plt.style.use('dark_background')\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['figure.facecolor'] = '#0E1117'\n",
    "plt.rcParams['axes.facecolor'] = '#0E1117'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc84b3",
   "metadata": {},
   "source": [
    "# ========================\n",
    "# LOAD KAGGLE DATASETS\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d92df4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine Quality Dataset: https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009\n",
    "wine = pd.read_csv('winequality-red.csv')\n",
    "\n",
    "# SMS Spam Collection: https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset\n",
    "spam = pd.read_csv('spam.csv', encoding='latin-1')[['v1', 'v2']]\n",
    "spam.columns = ['label', 'text']\n",
    "\n",
    "# Titanic Dataset: https://www.kaggle.com/competitions/titanic/data\n",
    "titanic = pd.read_csv('titanic.csv')[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec521f",
   "metadata": {},
   "source": [
    "# ========================\n",
    "# PREPROCESS DATASETS\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2005d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine Quality - Prepare for GaussianNB\n",
    "wine['quality_class'] = pd.cut(wine['quality'], bins=[0, 5, 7, 10], labels=['Low', 'Medium', 'High'])\n",
    "wine_features = wine.drop(['quality', 'quality_class'], axis=1)\n",
    "wine_target = wine['quality_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf1c713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spam - Prepare for MultinomialNB\n",
    "spam['label'] = spam['label'].map({'ham': 0, 'spam': 1})\n",
    "vectorizer = CountVectorizer(max_features=2000)\n",
    "X_spam = vectorizer.fit_transform(spam['text'])\n",
    "y_spam = spam['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673db545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic - Prepare for BernoulliNB\n",
    "titanic = titanic.dropna()\n",
    "titanic['Sex'] = titanic['Sex'].map({'male': 0, 'female': 1})\n",
    "titanic['Embarked'] = titanic['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "titanic['Age'] = pd.cut(titanic['Age'], bins=[0, 18, 35, 60, 100], labels=[0, 1, 2, 3])\n",
    "titanic['Fare'] = pd.cut(titanic['Fare'], bins=[0, 25, 50, 100, 1000], labels=[0, 1, 2, 3])\n",
    "titanic['Alone'] = ((titanic['SibSp'] + titanic['Parch']) == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d2f5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select binary features for BernoulliNB\n",
    "titanic_features = titanic[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Alone']]\n",
    "titanic_target = titanic['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8de5c9",
   "metadata": {},
   "source": [
    "# ========================\n",
    "# TRAIN MODELS\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e32b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GaussianNB - Wine Quality\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(\n",
    "    wine_features, wine_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9a3d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_wine_train, y_wine_train)\n",
    "y_wine_pred = gnb.predict(X_wine_test)\n",
    "wine_accuracy = accuracy_score(y_wine_test, y_wine_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec432a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB - Spam Classification\n",
    "X_spam_train, X_spam_test, y_spam_train, y_spam_test = train_test_split(\n",
    "    X_spam, y_spam, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d18ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_spam_train, y_spam_train)\n",
    "y_spam_pred = mnb.predict(X_spam_test)\n",
    "spam_accuracy = accuracy_score(y_spam_test, y_spam_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69f4d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BernoulliNB - Titanic Survival\n",
    "X_titanic_train, X_titanic_test, y_titanic_train, y_titanic_test = train_test_split(\n",
    "    titanic_features, titanic_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4c304cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_titanic_train, y_titanic_train)\n",
    "y_titanic_pred = bnb.predict(X_titanic_test)\n",
    "titanic_accuracy = accuracy_score(y_titanic_test, y_titanic_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1f79d5",
   "metadata": {},
   "source": [
    "# ========================\n",
    "# INTERACTIVE VISUALIZATION\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a41ec266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Set dark theme for plots\n",
    "plt.style.use('dark_background')\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['figure.facecolor'] = '#0E1117'\n",
    "plt.rcParams['axes.facecolor'] = '#0E1117'\n",
    "\n",
    "class NaiveBayesKaggleVisualizer:\n",
    "    def __init__(self):\n",
    "        # Create tabs with better styling\n",
    "        self.tab = widgets.Tab()\n",
    "        self.tab_titles = [\n",
    "            'üç∑ GaussianNB - Wine Quality', \n",
    "            'üìß MultinomialNB - Spam Detection', \n",
    "            'üö¢ BernoulliNB - Titanic Survival', \n",
    "            'üìä Comparison'\n",
    "        ]\n",
    "        \n",
    "        # Create output areas\n",
    "        self.outputs = [widgets.Output() for _ in range(4)]\n",
    "        \n",
    "        # Set tabs\n",
    "        self.tab.children = self.outputs\n",
    "        for i, title in enumerate(self.tab_titles):\n",
    "            self.tab.set_title(i, title)\n",
    "        \n",
    "        # Add styling to tabs\n",
    "        self.tab.add_class(\"custom-tabs\")\n",
    "        \n",
    "        # Initial display\n",
    "        display(self.tab)\n",
    "        \n",
    "        # Add CSS for styling\n",
    "        display(HTML(\"\"\"\n",
    "        <style>\n",
    "            .custom-tabs .widget-tab > .widget-tab-bar {\n",
    "                background: #1f2b38;\n",
    "                border-bottom: 1px solid #37414d;\n",
    "            }\n",
    "            .custom-tabs .widget-tab > .widget-tab-bar > .widget-tab-tab {\n",
    "                color: #aab7c4;\n",
    "                padding: 8px 15px;\n",
    "                transition: all 0.3s;\n",
    "                border-right: 1px solid #37414d;\n",
    "            }\n",
    "            .custom-tabs .widget-tab > .widget-tab-bar > .widget-tab-tab:hover {\n",
    "                background: #2a3a4a;\n",
    "            }\n",
    "            .custom-tabs .widget-tab > .widget-tab-bar > .widget-tab-tab.mod-active {\n",
    "                background: #2a3a4a;\n",
    "                color: white;\n",
    "                font-weight: bold;\n",
    "                border-bottom: 2px solid #4da6ff;\n",
    "            }\n",
    "        </style>\n",
    "        \"\"\"))\n",
    "        \n",
    "        # Render initial content\n",
    "        with self.outputs[0]:\n",
    "            self.render_wine_visualization()\n",
    "        with self.outputs[1]:\n",
    "            self.render_spam_visualization()\n",
    "        with self.outputs[2]:\n",
    "            self.render_titanic_visualization()\n",
    "        with self.outputs[3]:\n",
    "            self.render_comparison()\n",
    "    \n",
    "    def render_wine_visualization(self):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Header with dataset info\n",
    "        display(HTML(\"<h2 style='color:#4da6ff; border-bottom: 2px solid #4da6ff; padding-bottom: 10px;'>GaussianNB - Wine Quality Classification</h2>\"))\n",
    "        \n",
    "        # Performance metrics\n",
    "        metrics_html = f\"\"\"\n",
    "        <div style=\"background: #1f2b38; padding: 15px; border-radius: 8px; margin-bottom: 20px;\">\n",
    "            <h3 style=\"color: #4da6ff; margin-top: 0;\">Performance Metrics</h3>\n",
    "            <p><b>Accuracy:</b> <span style=\"color: #66ff66; font-size: 1.2em;\">{wine_accuracy:.2%}</span></p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(metrics_html))\n",
    "        \n",
    "        # Classification report as DataFrame\n",
    "        report = classification_report(y_wine_test, y_wine_pred, output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose().reset_index()\n",
    "        report_df.columns = ['Class', 'Precision', 'Recall', 'F1-Score', 'Support']\n",
    "        report_df = report_df.iloc[:-3]  # Remove averages\n",
    "        \n",
    "        # Create a GridSpec for layout\n",
    "        fig = plt.figure(figsize=(18, 15), facecolor='#0E1117')\n",
    "        gs = fig.add_gridspec(2, 2, height_ratios=[1, 1.5])\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        cm = confusion_matrix(y_wine_test, y_wine_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=['Low', 'Medium', 'High'], \n",
    "                    yticklabels=['Low', 'Medium', 'High'],\n",
    "                    ax=ax1)\n",
    "        ax1.set_title('Confusion Matrix', fontsize=14, color='white')\n",
    "        ax1.set_xlabel('Predicted', fontsize=12)\n",
    "        ax1.set_ylabel('Actual', fontsize=12)\n",
    "        \n",
    "        # Feature Importance\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': wine_features.columns,\n",
    "            'Importance': np.exp(gnb.theta_).mean(axis=0)\n",
    "        }).sort_values('Importance', ascending=True)\n",
    "        \n",
    "        bars = ax2.barh(feature_importance['Feature'], feature_importance['Importance'], \n",
    "                        color=plt.cm.viridis(np.linspace(0, 1, len(feature_importance))))\n",
    "        ax2.set_title('Feature Importance', fontsize=14, color='white')\n",
    "        ax2.set_xlabel('Importance', fontsize=12)\n",
    "        \n",
    "        # Add values to bars\n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            ax2.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                     f'{width:.2f}', \n",
    "                     ha='left', va='center', color='white')\n",
    "        \n",
    "        # PCA Visualization with Decision Boundaries\n",
    "        ax3 = fig.add_subplot(gs[1, :])\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(wine_features)\n",
    "        \n",
    "        # Create mesh grid for decision boundaries\n",
    "        x_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1\n",
    "        y_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                             np.linspace(y_min, y_max, 200))\n",
    "        \n",
    "        # Train a model on PCA components\n",
    "        gnb_pca = GaussianNB()\n",
    "        gnb_pca.fit(X_pca, wine_target)\n",
    "        Z = gnb_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = LabelEncoder().fit_transform(Z).reshape(xx.shape)\n",
    "        \n",
    "        # Plot decision boundaries\n",
    "        contour = ax3.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')\n",
    "        \n",
    "        # Plot data points\n",
    "        scatter = ax3.scatter(X_pca[:, 0], X_pca[:, 1], \n",
    "                             c=LabelEncoder().fit_transform(wine_target), \n",
    "                             cmap='viridis', s=50, edgecolors='white', alpha=0.8)\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(scatter, ax=ax3)\n",
    "        cbar.set_label('Wine Quality', color='white')\n",
    "        cbar.ax.yaxis.set_tick_params(color='white')\n",
    "        plt.setp(plt.getp(cbar.ax.axes, 'yticklabels'), color='white')\n",
    "        \n",
    "        ax3.set_title('PCA Visualization with Decision Boundaries', fontsize=14, color='white')\n",
    "        ax3.set_xlabel('Principal Component 1', fontsize=12)\n",
    "        ax3.set_ylabel('Principal Component 2', fontsize=12)\n",
    "        \n",
    "        # Add legend\n",
    "        legend_labels = ['Low Quality', 'Medium Quality', 'High Quality']\n",
    "        handles = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                             markerfacecolor=plt.cm.viridis(i/2), markersize=10) \n",
    "                  for i in range(3)]\n",
    "        ax3.legend(handles, legend_labels, loc='upper right', facecolor='#1f2b38', \n",
    "                  edgecolor='none', labelcolor='white')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Display classification report\n",
    "        display(HTML(\"<h3 style='color:#4da6ff;'>Detailed Classification Report</h3>\"))\n",
    "        display(report_df.style.background_gradient(cmap='Blues', subset=['Precision', 'Recall', 'F1-Score'])\n",
    "                .format({'Precision': '{:.2f}', 'Recall': '{:.2f}', 'F1-Score': '{:.2f}'})\n",
    "                .set_table_styles([{\n",
    "                    'selector': 'th',\n",
    "                    'props': [('background-color', '#1f2b38'), ('color', 'white')]\n",
    "                }]))\n",
    "    \n",
    "    def render_spam_visualization(self):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Header with dataset info\n",
    "        display(HTML(\"<h2 style='color:#ff9966; border-bottom: 2px solid #ff9966; padding-bottom: 10px;'>MultinomialNB - Spam Detection</h2>\"))\n",
    "        \n",
    "        # Performance metrics\n",
    "        metrics_html = f\"\"\"\n",
    "        <div style=\"background: #1f2b38; padding: 15px; border-radius: 8px; margin-bottom: 20px;\">\n",
    "            <h3 style=\"color: #ff9966; margin-top: 0;\">Performance Metrics</h3>\n",
    "            <p><b>Accuracy:</b> <span style=\"color: #66ff66; font-size: 1.2em;\">{spam_accuracy:.2%}</span></p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(metrics_html))\n",
    "        \n",
    "        # Create a GridSpec for layout\n",
    "        fig = plt.figure(figsize=(18, 16), facecolor='#0E1117')\n",
    "        gs = fig.add_gridspec(3, 2, height_ratios=[1, 1, 1.5])\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        cm = confusion_matrix(y_spam_test, y_spam_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', \n",
    "                    xticklabels=['Ham', 'Spam'], \n",
    "                    yticklabels=['Ham', 'Spam'],\n",
    "                    ax=ax1)\n",
    "        ax1.set_title('Confusion Matrix', fontsize=14, color='white')\n",
    "        ax1.set_xlabel('Predicted', fontsize=12)\n",
    "        ax1.set_ylabel('Actual', fontsize=12)\n",
    "        \n",
    "        # Classification report as DataFrame\n",
    "        report = classification_report(y_spam_test, y_spam_pred, output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose().reset_index()\n",
    "        report_df.columns = ['Class', 'Precision', 'Recall', 'F1-Score', 'Support']\n",
    "        report_df = report_df.iloc[:-3]  # Remove averages\n",
    "        \n",
    "        # Plot classification report\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        ax2.axis('off')\n",
    "        table = ax2.table(cellText=report_df.values, \n",
    "                         colLabels=report_df.columns, \n",
    "                         loc='center',\n",
    "                         cellLoc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(10)\n",
    "        table.scale(1, 1.5)\n",
    "        ax2.set_title('Classification Report', fontsize=14, color='white')\n",
    "        \n",
    "        # Top spam words\n",
    "        ax3 = fig.add_subplot(gs[1, 0])\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        spam_probs = mnb.feature_log_prob_[1, :]\n",
    "        top_spam_words = pd.DataFrame({\n",
    "            'Word': feature_names,\n",
    "            'Log Probability': spam_probs\n",
    "        }).sort_values('Log Probability', ascending=False).head(15)\n",
    "        \n",
    "        bars = ax3.barh(top_spam_words['Word'], top_spam_words['Log Probability'], \n",
    "                       color=plt.cm.Oranges(np.linspace(0.3, 1, len(top_spam_words))))\n",
    "        ax3.set_title('Top Spam Indicators', fontsize=14, color='white')\n",
    "        ax3.set_xlabel('Log Probability', fontsize=12)\n",
    "        \n",
    "        # Add values to bars\n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            ax3.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                     f'{width:.2f}', \n",
    "                     ha='left', va='center', color='white')\n",
    "        \n",
    "        # Top ham words\n",
    "        ax4 = fig.add_subplot(gs[1, 1])\n",
    "        ham_probs = mnb.feature_log_prob_[0, :]\n",
    "        top_ham_words = pd.DataFrame({\n",
    "            'Word': feature_names,\n",
    "            'Log Probability': ham_probs\n",
    "        }).sort_values('Log Probability', ascending=False).head(15)\n",
    "        \n",
    "        bars = ax4.barh(top_ham_words['Word'], top_ham_words['Log Probability'], \n",
    "                       color=plt.cm.Blues(np.linspace(0.3, 1, len(top_ham_words))))\n",
    "        ax4.set_title('Top Ham Indicators', fontsize=14, color='white')\n",
    "        ax4.set_xlabel('Log Probability', fontsize=12)\n",
    "        \n",
    "        # Add values to bars\n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            ax4.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                     f'{width:.2f}', \n",
    "                     ha='left', va='center', color='white')\n",
    "        \n",
    "        # Add additional analysis (without word cloud)\n",
    "        ax5 = fig.add_subplot(gs[2, :])\n",
    "        ax5.axis('off')\n",
    "        \n",
    "        # Create informative text\n",
    "        analysis_text = \"\"\"\n",
    "        <div style=\"background: #1f2b38; padding: 15px; border-radius: 8px; margin-top: 20px;\">\n",
    "            <h3 style=\"color: #ff9966; margin-top: 0;\">Analysis Insights</h3>\n",
    "            <p><b>Spam Indicators:</b> Words like 'free', 'win', 'prize', and 'call' are strong spam predictors</p>\n",
    "            <p><b>Ham Indicators:</b> Common conversational words like 'ok', 'sorry', and 'later' indicate legitimate messages</p>\n",
    "            <p><b>Model Performance:</b> MultinomialNB excels at text classification by leveraging word frequency patterns</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        ax5.text(0.5, 0.5, analysis_text, transform=ax5.transAxes, \n",
    "                ha='center', va='center', fontsize=12, color='white')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def render_titanic_visualization(self):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Header with dataset info\n",
    "        display(HTML(\"<h2 style='color:#cc66ff; border-bottom: 2px solid #cc66ff; padding-bottom: 10px;'>BernoulliNB - Titanic Survival Prediction</h2>\"))\n",
    "        \n",
    "        # Performance metrics\n",
    "        metrics_html = f\"\"\"\n",
    "        <div style=\"background: #1f2b38; padding: 15px; border-radius: 8px; margin-bottom: 20px;\">\n",
    "            <h3 style=\"color: #cc66ff; margin-top: 0;\">Performance Metrics</h3>\n",
    "            <p><b>Accuracy:</b> <span style=\"color: #66ff66; font-size: 1.2em;\">{titanic_accuracy:.2%}</span></p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(metrics_html))\n",
    "        \n",
    "        # Create a GridSpec for layout\n",
    "        fig = plt.figure(figsize=(18, 15), facecolor='#0E1117')\n",
    "        gs = fig.add_gridspec(2, 2, height_ratios=[1, 1.5])\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        cm = confusion_matrix(y_titanic_test, y_titanic_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', \n",
    "                    xticklabels=['Died', 'Survived'], \n",
    "                    yticklabels=['Died', 'Survived'],\n",
    "                    ax=ax1)\n",
    "        ax1.set_title('Confusion Matrix', fontsize=14, color='white')\n",
    "        ax1.set_xlabel('Predicted', fontsize=12)\n",
    "        ax1.set_ylabel('Actual', fontsize=12)\n",
    "        \n",
    "        # Feature Importance\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': titanic_features.columns,\n",
    "            'Importance': np.exp(bnb.feature_log_prob_[1, :] - bnb.feature_log_prob_[0, :])\n",
    "        }).sort_values('Importance', ascending=True)\n",
    "        \n",
    "        bars = ax2.barh(feature_importance['Feature'], feature_importance['Importance'], \n",
    "                        color=plt.cm.Purples(np.linspace(0.3, 1, len(feature_importance))))\n",
    "        ax2.set_title('Feature Importance (Log Odds Ratio)', fontsize=14, color='white')\n",
    "        ax2.set_xlabel('Importance', fontsize=12)\n",
    "        \n",
    "        # Add values to bars\n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            ax2.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                     f'{width:.2f}', \n",
    "                     ha='left', va='center', color='white')\n",
    "        \n",
    "        # Survival analysis\n",
    "        ax3 = fig.add_subplot(gs[1, :])\n",
    "        \n",
    "        # Create a grid for the survival plots\n",
    "        inner_gs = gs[1, :].subgridspec(1, 2, wspace=0.3)\n",
    "        ax3a = fig.add_subplot(inner_gs[0, 0])\n",
    "        ax3b = fig.add_subplot(inner_gs[0, 1])\n",
    "        \n",
    "        # Survival by Gender\n",
    "        sns.barplot(x='Sex', y='Survived', data=titanic, \n",
    "                   palette=['#ff6666', '#66b3ff'], ax=ax3a)\n",
    "        ax3a.set_title('Survival Rate by Gender', fontsize=14, color='white')\n",
    "        ax3a.set_xlabel('Gender', fontsize=12)\n",
    "        ax3a.set_ylabel('Survival Rate', fontsize=12)\n",
    "        ax3a.set_xticklabels(['Male', 'Female'])\n",
    "        ax3a.set_ylim(0, 1)\n",
    "        \n",
    "        # Add values on top of bars\n",
    "        for p in ax3a.patches:\n",
    "            ax3a.annotate(f'{p.get_height():.2f}', \n",
    "                         (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                         ha='center', va='center', \n",
    "                         xytext=(0, 10), \n",
    "                         textcoords='offset points',\n",
    "                         color='white')\n",
    "        \n",
    "        # Survival by Class\n",
    "        sns.barplot(x='Pclass', y='Survived', data=titanic, \n",
    "                   palette=['#ff9999', '#66c2a5', '#8da0cb'], ax=ax3b)\n",
    "        ax3b.set_title('Survival Rate by Passenger Class', fontsize=14, color='white')\n",
    "        ax3b.set_xlabel('Passenger Class', fontsize=12)\n",
    "        ax3b.set_ylabel('Survival Rate', fontsize=12)\n",
    "        ax3b.set_ylim(0, 1)\n",
    "        \n",
    "        # Add values on top of bars\n",
    "        for p in ax3b.patches:\n",
    "            ax3b.annotate(f'{p.get_height():.2f}', \n",
    "                         (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                         ha='center', va='center', \n",
    "                         xytext=(0, 10), \n",
    "                         textcoords='offset points',\n",
    "                         color='white')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Display classification report\n",
    "        display(HTML(\"<h3 style='color:#cc66ff;'>Detailed Classification Report</h3>\"))\n",
    "        report = classification_report(y_titanic_test, y_titanic_pred, output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose().reset_index()\n",
    "        report_df.columns = ['Class', 'Precision', 'Recall', 'F1-Score', 'Support']\n",
    "        report_df = report_df.iloc[:-3]  # Remove averages\n",
    "        \n",
    "        display(report_df.style.background_gradient(cmap='Purples', subset=['Precision', 'Recall', 'F1-Score'])\n",
    "                .format({'Precision': '{:.2f}', 'Recall': '{:.2f}', 'F1-Score': '{:.2f}'})\n",
    "                .set_table_styles([{\n",
    "                    'selector': 'th',\n",
    "                    'props': [('background-color', '#1f2b38'), ('color', 'white')]\n",
    "                }]))\n",
    "    \n",
    "    def render_comparison(self):\n",
    "        clear_output(wait=True)\n",
    "        display(HTML(\"<h2 style='color:#66b3ff; border-bottom: 2px solid #66b3ff; padding-bottom: 10px;'>Naive Bayes Classifiers Comparison</h2>\"))\n",
    "        \n",
    "        # Create comparison table\n",
    "        results = pd.DataFrame({\n",
    "            'Classifier': ['GaussianNB', 'MultinomialNB', 'BernoulliNB'],\n",
    "            'Dataset': ['Wine Quality', 'SMS Spam', 'Titanic Survival'],\n",
    "            'Accuracy': [wine_accuracy, spam_accuracy, titanic_accuracy],\n",
    "            'Data Type': ['Continuous', 'Text Counts', 'Binary'],\n",
    "            'Features': ['Chemical Properties', 'Word Frequencies', 'Categorical Variables']\n",
    "        })\n",
    "        \n",
    "        # Display table with styling\n",
    "        display(HTML(\"<h3 style='color:#66b3ff;'>Performance Comparison</h3>\"))\n",
    "        display(results.style.background_gradient(cmap='Blues', subset=['Accuracy'])\n",
    "                .format({'Accuracy': '{:.2%}'})\n",
    "                .set_table_styles([{\n",
    "                    'selector': 'th',\n",
    "                    'props': [('background-color', '#1f2b38'), ('color', 'white')]\n",
    "                }]))\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(18, 15), facecolor='#0E1117')\n",
    "        \n",
    "        # Accuracy comparison\n",
    "        sns.barplot(x='Classifier', y='Accuracy', data=results, \n",
    "                   palette=['#4da6ff', '#ff9966', '#cc66ff'], ax=ax[0, 0])\n",
    "        ax[0, 0].set_title('Accuracy Comparison', fontsize=14, color='white')\n",
    "        ax[0, 0].set_xlabel('Classifier Type', fontsize=12)\n",
    "        ax[0, 0].set_ylabel('Accuracy', fontsize=12)\n",
    "        ax[0, 0].set_ylim(0, 1)\n",
    "        \n",
    "        # Add values on top of bars\n",
    "        for p in ax[0, 0].patches:\n",
    "            ax[0, 0].annotate(f'{p.get_height():.2%}', \n",
    "                             (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                             ha='center', va='center', \n",
    "                             xytext=(0, 10), \n",
    "                             textcoords='offset points',\n",
    "                             color='white')\n",
    "        \n",
    "        # Data distribution comparison\n",
    "        # Wine data (Gaussian)\n",
    "        pca = PCA(n_components=2)\n",
    "        wine_pca = pca.fit_transform(wine_features)\n",
    "        scatter1 = ax[0, 1].scatter(wine_pca[:, 0], wine_pca[:, 1], \n",
    "                                   c=LabelEncoder().fit_transform(wine_target), \n",
    "                                   cmap='viridis', s=30, alpha=0.7)\n",
    "        ax[0, 1].set_title('GaussianNB: Wine Quality Distribution', fontsize=14, color='white')\n",
    "        ax[0, 1].set_xlabel('PC1', fontsize=12)\n",
    "        ax[0, 1].set_ylabel('PC2', fontsize=12)\n",
    "        \n",
    "        # Spam data (Multinomial)\n",
    "        # Using PCA for visualization\n",
    "        spam_pca = PCA(n_components=2).fit_transform(X_spam.toarray())\n",
    "        colors = ['#4da6ff' if label == 0 else '#ff9966' for label in y_spam[:1000]]\n",
    "        ax[1, 0].scatter(spam_pca[:1000, 0], spam_pca[:1000, 1], \n",
    "                        c=colors, s=20, alpha=0.6)\n",
    "        ax[1, 0].set_title('MultinomialNB: Spam/Ham Distribution', fontsize=14, color='white')\n",
    "        ax[1, 0].set_xlabel('PC1', fontsize=12)\n",
    "        ax[1, 0].set_ylabel('PC2', fontsize=12)\n",
    "        \n",
    "        # Add legend for spam/ham\n",
    "        ham_patch = plt.Line2D([0], [0], marker='o', color='w', \n",
    "                              markerfacecolor='#4da6ff', markersize=10, label='Ham')\n",
    "        spam_patch = plt.Line2D([0], [0], marker='o', color='w', \n",
    "                               markerfacecolor='#ff9966', markersize=10, label='Spam')\n",
    "        ax[1, 0].legend(handles=[ham_patch, spam_patch], \n",
    "                       loc='upper right', \n",
    "                       facecolor='#1f2b38', \n",
    "                       edgecolor='none', \n",
    "                       labelcolor='white')\n",
    "        \n",
    "        # Titanic data (Bernoulli) - Survival by gender and class\n",
    "        survival_rates = titanic.groupby(['Pclass', 'Sex'])['Survived'].mean().reset_index()\n",
    "        survival_rates['Sex'] = survival_rates['Sex'].map({0: 'Male', 1: 'Female'})\n",
    "        \n",
    "        # Create a grouped bar plot\n",
    "        sns.barplot(x='Pclass', y='Survived', hue='Sex', \n",
    "                   data=survival_rates, \n",
    "                   palette={'Male': '#cc66ff', 'Female': '#66ffcc'}, \n",
    "                   ax=ax[1, 1])\n",
    "        ax[1, 1].set_title('BernoulliNB: Survival Rate by Class & Gender', fontsize=14, color='white')\n",
    "        ax[1, 1].set_xlabel('Passenger Class', fontsize=12)\n",
    "        ax[1, 1].set_ylabel('Survival Rate', fontsize=12)\n",
    "        ax[1, 1].set_ylim(0, 1)\n",
    "        ax[1, 1].legend(title='Gender', facecolor='#1f2b38', edgecolor='none', labelcolor='white')\n",
    "        \n",
    "        # Add values on top of bars\n",
    "        for p in ax[1, 1].patches:\n",
    "            ax[1, 1].annotate(f'{p.get_height():.2f}', \n",
    "                             (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                             ha='center', va='center', \n",
    "                             xytext=(0, 10), \n",
    "                             textcoords='offset points',\n",
    "                             color='white')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Algorithm comparison table\n",
    "        display(HTML(\"<h3 style='color:#66b3ff;'>Algorithm Characteristics</h3>\"))\n",
    "        algorithm_data = {\n",
    "            \"Classifier\": [\"GaussianNB\", \"MultinomialNB\", \"BernoulliNB\"],\n",
    "            \"Best For\": [\"Continuous features\", \"Discrete counts\", \"Binary features\"],\n",
    "            \"Data Type\": [\"Real-valued features\", \"Positive integers\", \"0/1 or boolean\"],\n",
    "            \"Key Assumption\": [\"Features follow normal distribution\", \n",
    "                              \"Features represent frequencies/counts\", \n",
    "                              \"Features are independent binary variables\"],\n",
    "            \"Strengths\": [\"Simple, efficient for numerical data\", \n",
    "                         \"Excellent for text classification\", \n",
    "                         \"Fast, works well with high-dimensional binary data\"],\n",
    "            \"Weaknesses\": [\"Sensitive to non-Gaussian distributions\", \n",
    "                          \"Requires integer counts\", \n",
    "                          \"May oversimplify continuous features\"]\n",
    "        }\n",
    "        \n",
    "        algorithm_df = pd.DataFrame(algorithm_data)\n",
    "        display(algorithm_df.style.set_properties(**{\n",
    "                    'background-color': '#1f2b38',\n",
    "                    'color': 'white',\n",
    "                    'border-color': '#37414d'\n",
    "                })\n",
    "                .set_table_styles([{\n",
    "                    'selector': 'th',\n",
    "                    'props': [('background-color', '#1f2b38'), ('color', 'white'), ('border', '1px solid #37414d')]\n",
    "                }, {\n",
    "                    'selector': 'td',\n",
    "                    'props': [('border', '1px solid #37414d')]\n",
    "                }]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809839ee",
   "metadata": {},
   "source": [
    "# ========================\n",
    "# SUMMARY TABLE\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2875cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_table():\n",
    "    \"\"\"Create comparison table of Naive Bayes classifiers\"\"\"\n",
    "    data = {\n",
    "        \"Classifier\": [\"GaussianNB\", \"MultinomialNB\", \"BernoulliNB\"],\n",
    "        \"Best For\": [\"Continuous features\", \"Discrete counts\", \"Binary features\"],\n",
    "        \"Data Type\": [\"Real-valued features\", \"Positive integers\", \"0/1 or boolean\"],\n",
    "        \"Key Assumption\": [\"Features follow normal distribution\", \n",
    "                          \"Features represent frequencies/counts\", \n",
    "                          \"Features are independent binary variables\"],\n",
    "        \"Kaggle Dataset\": [\"Wine Quality\", \"SMS Spam Detection\", \"Titanic Survival\"],\n",
    "        \"Accuracy\": [f\"{wine_accuracy:.2%}\", f\"{spam_accuracy:.2%}\", f\"{titanic_accuracy:.2%}\"]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64023c6a",
   "metadata": {},
   "source": [
    "# ========================\n",
    "# RUN THE VISUALIZATION\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ede3f3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e6497_row0_col0, #T_e6497_row0_col1, #T_e6497_row0_col2, #T_e6497_row0_col3, #T_e6497_row0_col4, #T_e6497_row0_col5, #T_e6497_row1_col0, #T_e6497_row1_col1, #T_e6497_row1_col2, #T_e6497_row1_col3, #T_e6497_row1_col4, #T_e6497_row1_col5, #T_e6497_row2_col0, #T_e6497_row2_col1, #T_e6497_row2_col2, #T_e6497_row2_col3, #T_e6497_row2_col4, #T_e6497_row2_col5 {\n",
       "  background-color: #0E1117;\n",
       "  color: white;\n",
       "  border-color: #333333;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e6497\">\n",
       "  <caption>Naive Bayes Classifiers Comparison</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e6497_level0_col0\" class=\"col_heading level0 col0\" >Classifier</th>\n",
       "      <th id=\"T_e6497_level0_col1\" class=\"col_heading level0 col1\" >Best For</th>\n",
       "      <th id=\"T_e6497_level0_col2\" class=\"col_heading level0 col2\" >Data Type</th>\n",
       "      <th id=\"T_e6497_level0_col3\" class=\"col_heading level0 col3\" >Key Assumption</th>\n",
       "      <th id=\"T_e6497_level0_col4\" class=\"col_heading level0 col4\" >Kaggle Dataset</th>\n",
       "      <th id=\"T_e6497_level0_col5\" class=\"col_heading level0 col5\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e6497_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e6497_row0_col0\" class=\"data row0 col0\" >GaussianNB</td>\n",
       "      <td id=\"T_e6497_row0_col1\" class=\"data row0 col1\" >Continuous features</td>\n",
       "      <td id=\"T_e6497_row0_col2\" class=\"data row0 col2\" >Real-valued features</td>\n",
       "      <td id=\"T_e6497_row0_col3\" class=\"data row0 col3\" >Features follow normal distribution</td>\n",
       "      <td id=\"T_e6497_row0_col4\" class=\"data row0 col4\" >Wine Quality</td>\n",
       "      <td id=\"T_e6497_row0_col5\" class=\"data row0 col5\" >71.88%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6497_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e6497_row1_col0\" class=\"data row1 col0\" >MultinomialNB</td>\n",
       "      <td id=\"T_e6497_row1_col1\" class=\"data row1 col1\" >Discrete counts</td>\n",
       "      <td id=\"T_e6497_row1_col2\" class=\"data row1 col2\" >Positive integers</td>\n",
       "      <td id=\"T_e6497_row1_col3\" class=\"data row1 col3\" >Features represent frequencies/counts</td>\n",
       "      <td id=\"T_e6497_row1_col4\" class=\"data row1 col4\" >SMS Spam Detection</td>\n",
       "      <td id=\"T_e6497_row1_col5\" class=\"data row1 col5\" >98.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6497_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e6497_row2_col0\" class=\"data row2 col0\" >BernoulliNB</td>\n",
       "      <td id=\"T_e6497_row2_col1\" class=\"data row2 col1\" >Binary features</td>\n",
       "      <td id=\"T_e6497_row2_col2\" class=\"data row2 col2\" >0/1 or boolean</td>\n",
       "      <td id=\"T_e6497_row2_col3\" class=\"data row2 col3\" >Features are independent binary variables</td>\n",
       "      <td id=\"T_e6497_row2_col4\" class=\"data row2 col4\" >Titanic Survival</td>\n",
       "      <td id=\"T_e6497_row2_col5\" class=\"data row2 col5\" >73.43%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d58242b260>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54e76c850234b7d8f145be4c6d217bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output()), selected_index=0, titles=('üç∑ GaussianNB - Wine Quality'‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .custom-tabs .widget-tab > .widget-tab-bar {\n",
       "                background: #1f2b38;\n",
       "                border-bottom: 1px solid #37414d;\n",
       "            }\n",
       "            .custom-tabs .widget-tab > .widget-tab-bar > .widget-tab-tab {\n",
       "                color: #aab7c4;\n",
       "                padding: 8px 15px;\n",
       "                transition: all 0.3s;\n",
       "                border-right: 1px solid #37414d;\n",
       "            }\n",
       "            .custom-tabs .widget-tab > .widget-tab-bar > .widget-tab-tab:hover {\n",
       "                background: #2a3a4a;\n",
       "            }\n",
       "            .custom-tabs .widget-tab > .widget-tab-bar > .widget-tab-tab.mod-active {\n",
       "                background: #2a3a4a;\n",
       "                color: white;\n",
       "                font-weight: bold;\n",
       "                border-bottom: 2px solid #4da6ff;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display summary table\n",
    "summary_table = create_summary_table()\n",
    "display(summary_table.style.set_properties(**{\n",
    "    'background-color': '#0E1117',\n",
    "    'color': 'white',\n",
    "    'border-color': '#333333'\n",
    "}).set_caption(\"Naive Bayes Classifiers Comparison\"))\n",
    "\n",
    "# Start the interactive visualizer\n",
    "visualizer = NaiveBayesKaggleVisualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1cc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0121192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
